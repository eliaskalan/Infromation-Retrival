{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BgRI1oTYjOS"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import gensim\n",
        "import string\n",
        "from itertools import groupby\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "random.seed(123)\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"pg3300.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    fileString = file.read()"
      ],
      "metadata": {
        "id": "KdaKRt7uYsyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def paragraph(lines):\n",
        "    for group_separator, line_iteration in groupby(lines.splitlines(True), key=str.isspace):\n",
        "        if not group_separator:\n",
        "            yield ''.join(line_iteration)"
      ],
      "metadata": {
        "id": "HodN7Gm-Ywn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_paragraphs(file, filter_word):\n",
        "    paragraph_list = []\n",
        "    for p in paragraph(file):\n",
        "        if filter_word.casefold() not in p.casefold():\n",
        "            paragraph_list.append(p)\n",
        "    return paragraph_list"
      ],
      "metadata": {
        "id": "jMgfoVsQYymC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_document(documents):\n",
        "    tokenized_documents = []\n",
        "    for d in documents:\n",
        "        # Also the punctuation is removed\n",
        "        tokenized_documents.append(re.sub(\"[^\\w]\", \" \", d).split())\n",
        "    return tokenized_documents"
      ],
      "metadata": {
        "id": "d0zxIZlrY0tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem(document):\n",
        "    stemmed_document = []\n",
        "    for d in document:\n",
        "        words_stemmed = []\n",
        "        for word in d:\n",
        "            words_stemmed.append(stemmer.stem(word).lower())\n",
        "        stemmed_document.append(words_stemmed)\n",
        "    return stemmed_document"
      ],
      "metadata": {
        "id": "3N8iN2oMY2xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = make_paragraphs(fileString, \"Gutenberg\")\n",
        "# Copy of the original document\n",
        "documents_edited = documents.copy()\n",
        "documents_edited = tokenize_document(documents_edited)\n",
        "documents_edited = stem(documents_edited)"
      ],
      "metadata": {
        "id": "immuiXEEY6NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopString = 'a,able,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,' \\\n",
        "             'cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,' \\\n",
        "             'how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,' \\\n",
        "             'not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,' \\\n",
        "             'their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,' \\\n",
        "             'who,whom,why,will,with,would,yet,you,your'\n",
        "stop_word_list = stopString.split(',')\n",
        "dictionary = gensim.corpora.Dictionary(documents_edited)"
      ],
      "metadata": {
        "id": "tVaU9o2XY-qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stop_word_ids(stop_words, dictionary):\n",
        "    ids = []\n",
        "    for word in stop_words:\n",
        "        try:\n",
        "            ids.append(dictionary.token2id[word])\n",
        "        except:\n",
        "            pass\n",
        "    return ids"
      ],
      "metadata": {
        "id": "hy7_n4k6ZBJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bags=[]\n",
        "# list of the id's\n",
        "stop_ids = stop_word_ids(stop_word_list, dictionary)\n",
        "\n",
        "# filter out the stopwords in the dictionary\n",
        "dictionary.filter_tokens(stop_ids)\n",
        "\n",
        "for p in documents_edited:\n",
        "    bags.append(dictionary.doc2bow(p))"
      ],
      "metadata": {
        "id": "dbeptDR9ZEFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3"
      ],
      "metadata": {
        "id": "nxskGGcNZJ2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1\n",
        "tfidf_model = gensim.models.TfidfModel(bags)\n",
        "# 3.2\n",
        "tfidf_corpus = tfidf_model[bags]\n",
        "# 3.3\n",
        "matrix_sim = gensim.similarities.MatrixSimilarity(tfidf_corpus)\n",
        "# 3.4\n",
        "lsi_model = gensim.models.LsiModel(tfidf_corpus, id2word=dictionary, num_topics=100)\n",
        "lsi_corpus = lsi_model[bags]\n",
        "lsi_matrix = gensim.similarities.MatrixSimilarity(lsi_corpus)\n",
        "# 3.5\n",
        "print(\"First 3 LSI topics\")\n",
        "topics = lsi_model.show_topics(3)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd6Tcc1wZMNE",
        "outputId": "64c851a8-1ca5-489d-d34a-3f80601eeb8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
            "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 3 LSI topics\n",
            "(0, '0.146*\"labour\" + 0.137*\"price\" + 0.127*\"produc\" + 0.127*\"employ\" + 0.122*\"capit\" + 0.121*\"tax\" + 0.121*\"countri\" + 0.118*\"trade\" + 0.118*\"hi\" + 0.115*\"land\"')\n",
            "(1, '-0.258*\"rent\" + -0.231*\"labour\" + -0.207*\"land\" + 0.205*\"silver\" + 0.191*\"gold\" + -0.176*\"profit\" + -0.174*\"stock\" + -0.161*\"employ\" + -0.155*\"capit\" + 0.152*\"coin\"')\n",
            "(2, '0.352*\"price\" + 0.227*\"silver\" + -0.211*\"trade\" + 0.199*\"quantiti\" + -0.167*\"coloni\" + 0.163*\"labour\" + 0.152*\"valu\" + 0.150*\"gold\" + -0.137*\"capit\" + 0.133*\"corn\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4"
      ],
      "metadata": {
        "id": "04J2nAddZUnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuations_list(word_list):\n",
        "    words = []\n",
        "    for word in word_list:\n",
        "        w = \"\"\n",
        "        for char in word:\n",
        "            if (string.punctuation + \"\\n\\r\\t\").__contains__(char):\n",
        "                if w != \"\":\n",
        "                    words.append(w.lower())\n",
        "                    w = \"\"\n",
        "                continue\n",
        "            w += char\n",
        "        if w != \"\":\n",
        "            words.append(w)\n",
        "    return words"
      ],
      "metadata": {
        "id": "XyjdzE5_ZWAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem_list(words):\n",
        "    for i, word in enumerate(words):\n",
        "        words[i] = stemmer.stem(word.lower())\n",
        "    return words"
      ],
      "metadata": {
        "id": "KL5-fG3KZYHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(query):\n",
        "    query = query.lower()\n",
        "    query = query.split()\n",
        "    query = remove_punctuations_list(query)\n",
        "    query = stem_list(query)\n",
        "    return query"
      ],
      "metadata": {
        "id": "TA0vgfpdZbXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1\n",
        "query = \"What is the function of money?\"\n",
        "query = preprocessing(query)\n",
        "query = dictionary.doc2bow(query)"
      ],
      "metadata": {
        "id": "pgCnSL96ZmPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2\n",
        "tfidf_index = tfidf_model[query]\n",
        "print(\"\\nTF_IDF Weights\")\n",
        "for word in tfidf_index:\n",
        "    word_index = word[0]\n",
        "    word_weight = word[1]\n",
        "    print(\"index\", word_index, \", word:\", dictionary.get(word_index, word_weight), \", weight:\", word_weight)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeYxBHzdZoPh",
        "outputId": "6fa41351-30d5-4044-9357-6bbbf641419b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF_IDF Weights\n",
            "index 52 , word: money , weight: 0.3126887267826082\n",
            "index 1153 , word: function , weight: 0.9498556522667386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.3\n",
        "print(\"\\n Top 3 Relevant Documents\", end=\"\")\n",
        "# similar documents\n",
        "doc2sim = enumerate(matrix_sim[tfidf_index])\n",
        "# sorting\n",
        "top_results = sorted(doc2sim, key=lambda x: x[1], reverse=True)[:3]\n",
        "# printing top 3 most relevant documents\n",
        "for result in top_results:\n",
        "    doc = documents[result[0]]\n",
        "    doc = doc.split('\\n')\n",
        "    print(\"\\n[Paragraph %d]\" % result[0])\n",
        "    # printing only 5 lines of the document\n",
        "    for line in range(4):\n",
        "      try:\n",
        "        print(doc[line])\n",
        "      except:\n",
        "        pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCTOmLkmZrcw",
        "outputId": "19b7b850-e58e-47f9-9fe6-215fd631b08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Top 3 Relevant Documents\n",
            "[Paragraph 682]\n",
            "      The general stock of any country or society is the same with that of all\n",
            "      its inhabitants or members; and, therefore, naturally divides itself into\n",
            "      the same three portions, each of which has a distinct function or office.\n",
            "\n",
            "\n",
            "[Paragraph 993]\n",
            "      That wealth consists in money, or in gold and silver, is a popular notion\n",
            "      which naturally arises from the double function of money, as the\n",
            "      instrument of commerce, and as the measure of value. In consequence of its\n",
            "      being the instrument of commerce, when we have money we can more readily\n",
            "\n",
            "[Paragraph 817]\n",
            "      Whatever part of his stock a man employs as a capital, he always expects\n",
            "      it to be replaced to him with a profit. He employs it, therefore, in\n",
            "      maintaining productive hands only; and after having served in the function\n",
            "      of a capital to him, it constitutes a revenue to them. Whenever he employs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4.4\n",
        "print(\"\\n[4.4.1 - Top 3 Topics with the most Significant Weights]\",end=\"\")\n",
        "lsi_query = lsi_model[query]\n",
        "topics = sorted(lsi_query, key=lambda kv: -abs(kv[1]))[:3]\n",
        "for topic in enumerate(topics):\n",
        "    t = topic[1][0]\n",
        "    print(\"\\n[Topic %d]\" % t)\n",
        "    print(lsi_model.show_topics()[t])\n",
        "\n",
        "print(\"\\n[4.4.2 - Top 3 Most Relevant Paragraphs]\", end=\"\")\n",
        "lsi_doc2sim = enumerate(lsi_matrix[lsi_query])\n",
        "lsi_documents = sorted(lsi_doc2sim, key=lambda kv: -abs(kv[1]))[:3]\n",
        "for result in lsi_documents:\n",
        "    doc = documents[result[0]]\n",
        "    doc = doc.split('\\n')\n",
        "    print(\"\\n[Paragraph %d]\" %result[0])\n",
        "    for line in range(5):\n",
        "        print(doc[line])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKUScY1paXW0",
        "outputId": "6af31989-ba32-4132-e902-9db12e128577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4.4.1 - Top 3 Topics with the most Significant Weights]\n",
            "[Topic 4]\n",
            "(4, '0.262*\"bank\" + 0.212*\"circul\" + -0.212*\"price\" + 0.181*\"money\" + 0.174*\"capit\" + -0.170*\"corn\" + 0.168*\"gold\" + -0.160*\"import\" + -0.160*\"export\" + 0.136*\"coin\"')\n",
            "\n",
            "[Topic 12]\n",
            "(12, '-0.353*\"bank\" + 0.209*\"coin\" + -0.184*\"money\" + -0.175*\"tax\" + -0.164*\"commod\" + 0.156*\"profit\" + -0.148*\"paper\" + 0.144*\"duti\" + 0.139*\"silver\" + 0.134*\"gold\"')\n",
            "\n",
            "[Topic 16]\n",
            "(16, '0.303*\"coloni\" + 0.263*\"circul\" + -0.190*\"increas\" + 0.178*\"price\" + -0.149*\"coin\" + -0.146*\"cent\" + 0.143*\"money\" + -0.143*\"per\" + 0.134*\"work\" + 0.130*\"materi\"')\n",
            "\n",
            "[4.4.2 - Top 3 Most Relevant Paragraphs]\n",
            "[Paragraph 993]\n",
            "      That wealth consists in money, or in gold and silver, is a popular notion\n",
            "      which naturally arises from the double function of money, as the\n",
            "      instrument of commerce, and as the measure of value. In consequence of its\n",
            "      being the instrument of commerce, when we have money we can more readily\n",
            "      obtain whatever else we have occasion for, than by means of any other\n",
            "\n",
            "[Paragraph 1008]\n",
            "      No complaint, however, is more common than that of a scarcity of money.\n",
            "      Money, like wine, must always be scarce with those who have neither\n",
            "      wherewithal to buy it, nor credit to borrow it. Those who have either,\n",
            "      will seldom be in want either of the money, or of the wine which they have\n",
            "      occasion for. This complaint, however, of the scarcity of money, is not\n",
            "\n",
            "[Paragraph 1009]\n",
            "      It would be too ridiculous to go about seriously to prove, that wealth\n",
            "      does not consist in money, or in gold and silver; but in what money\n",
            "      purchases, and is valuable only for purchasing. Money, no doubt, makes\n",
            "      always a part of the national capital; but it has already been shown that\n",
            "      it generally makes but a small part, and always the most unprofitable part\n"
          ]
        }
      ]
    }
  ]
}