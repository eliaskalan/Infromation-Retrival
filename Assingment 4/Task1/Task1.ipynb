{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1FYDkRj3Kuv",
        "outputId": "0337831b-6b29-46d9-906a-1a9be3202f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXdVL3Mg2b_w",
        "outputId": "d3f7dd95-dd78-4108-8f61-161925db058b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Although we know much more about the human brain than we did even\\n',\n",
              " 'ten years ago, the thinking it engages in remains pretty much a total\\n',\n",
              " 'mystery. It is like a big jigsaw puzzle where we can see many of the\\n',\n",
              " 'pieces, but cannot yet put them together. There is so much about us\\n',\n",
              " 'that we do not understand at all.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "file= open('doc.txt',encoding='utf8')\n",
        "read=file.read()\n",
        "file.seek(0)\n",
        "read\n",
        "  \n",
        "# to obtain the\n",
        "# number of lines\n",
        "# in file\n",
        "line = 1\n",
        "for word in read:\n",
        "    if word == '\\n':\n",
        "        line += 1\n",
        "  \n",
        "# create a list to\n",
        "# store each line as\n",
        "# an element of list\n",
        "array = []\n",
        "for i in range(line):\n",
        "    array.append(file.readline())\n",
        "array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
        "for ele in read:  \n",
        "    if ele in punc:  \n",
        "        read = read.replace(ele, \" \")  \n",
        "          \n",
        "read\n",
        "  \n",
        "# to maintain uniformity\n",
        "read=read.lower()                    \n",
        "read"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "PCfbVVI-2qaL",
        "outputId": "1d48c14f-33a2-484a-d6d0-b2ad0fe48499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'although we know much more about the human brain than we did even\\nten years ago  the thinking it engages in remains pretty much a total\\nmystery  it is like a big jigsaw puzzle where we can see many of the\\npieces  but cannot yet put them together  there is so much about us\\nthat we do not understand at all '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(1):\n",
        "    # this will convert\n",
        "    # the word into tokens\n",
        "    text_tokens = word_tokenize(read)\n",
        "  \n",
        "tokens_without_sw = [\n",
        "    word for word in text_tokens if not word in stopwords.words()]\n",
        "  \n",
        "print(tokens_without_sw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA15tOqX2twF",
        "outputId": "ac171205-f78b-44d3-ab26-459f3a06ce2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['human', 'brain', 'ten', 'years', 'ago', 'engages', 'remains', 'pretty', 'total', 'mystery', 'big', 'jigsaw', 'puzzle', 'pieces', 'put', 'understand']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict = {}\n",
        "  \n",
        "for i in range(line):\n",
        "    check = array[i].lower()\n",
        "    for item in tokens_without_sw:\n",
        "  \n",
        "        if item in check:\n",
        "            if item not in dict:\n",
        "                dict[item] = []\n",
        "  \n",
        "            if item in dict:\n",
        "                dict[item].append(i+1)\n",
        "  \n",
        "print(dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM-IVKlKoX29",
        "outputId": "941e3679-6cd2-4557-a3bb-8c7c4a130c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'human': [1], 'brain': [1], 'ten': [2], 'years': [2], 'ago': [2], 'engages': [2], 'remains': [2], 'pretty': [2], 'total': [2], 'mystery': [3], 'big': [3], 'jigsaw': [3], 'puzzle': [3], 'pieces': [4], 'put': [4], 'understand': [5]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " inverted list with block addressing\n",
        " "
      ],
      "metadata": {
        "id": "jbDGvra7oYqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]"
      ],
      "metadata": {
        "id": "ECLteD48maq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block=[]\n",
        "block=list(chunks(text_tokens,4))"
      ],
      "metadata": {
        "id": "mFb-jLOUmZFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk={}\n",
        "for i in range(len(block)):\n",
        "    check = block[i]\n",
        "    for item in tokens_without_sw:\n",
        "  \n",
        "        if item in check:\n",
        "            if item not in blk:\n",
        "                blk[item] = []\n",
        "  \n",
        "            if item in blk:\n",
        "              if not i+1 in blk[item]:\n",
        "                blk[item].append(i+1)"
      ],
      "metadata": {
        "id": "lRI1c6VclJGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRrPH-KRjqI2",
        "outputId": "4846d1a9-d011-4087-e0ac-ba73368cd6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intelligent': [1],\n",
              " 'behavior': [1],\n",
              " 'product': [2],\n",
              " 'mind': [3, 4],\n",
              " 'human': [5],\n",
              " 'brain': [6]}"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr={}\n",
        "for i in range(len(block)):\n",
        "    check = block[i]\n",
        "    for item in tokens_without_sw:\n",
        "  \n",
        "        if item in check:\n",
        "            if item not in tr:\n",
        "                tr[i] = item\n",
        "  \n",
        "            if item in tr:\n",
        "              if not i+1 in tr[item]:\n",
        "                tr[i].append(item)"
      ],
      "metadata": {
        "id": "Gq0gw_mau15s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKO34Azwu_vm",
        "outputId": "d7d377ba-b33d-49a0-d238-bb098bd7478a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'behavior', 1: 'product', 2: 'mind', 3: 'mind', 4: 'human', 5: 'brain'}"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from suffix_tree import Tree\n",
        "tree = Tree(tr)\n",
        "tree.find(\"aplac\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE-X2cCcukwm",
        "outputId": "2eeb7c91-09af-47ec-fc39-1ea3fb8233c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, sub=\"\", children=None):\n",
        "        self.sub = sub\n",
        "        self.ch = children or []\n",
        "\n",
        "class SuffixTree:\n",
        "    def __init__(self, str):\n",
        "        self.nodes = [Node()]\n",
        "        for i in range(len(str)):\n",
        "            self.addSuffix(str[i:])\n",
        "\n",
        "    def addSuffix(self, suf):\n",
        "        n = 0\n",
        "        i = 0\n",
        "        while i < len(suf):\n",
        "            b = suf[i]\n",
        "            x2 = 0\n",
        "            while True:\n",
        "                children = self.nodes[n].ch\n",
        "                if x2 == len(children):\n",
        "                    # no matching child, remainder of suf becomes new node\n",
        "                    n2 = len(self.nodes)\n",
        "                    self.nodes.append(Node(suf[i:], []))\n",
        "                    self.nodes[n].ch.append(n2)\n",
        "                    return\n",
        "                n2 = children[x2]\n",
        "                if self.nodes[n2].sub[0] == b:\n",
        "                    break\n",
        "                x2 = x2 + 1\n",
        "\n",
        "            # find prefix of remaining suffix in common with child\n",
        "            sub2 = self.nodes[n2].sub\n",
        "            j = 0\n",
        "            while j < len(sub2):\n",
        "                if suf[i + j] != sub2[j]:\n",
        "                    # split n2\n",
        "                    n3 = n2\n",
        "                    # new node for the part in common\n",
        "                    n2 = len(self.nodes)\n",
        "                    self.nodes.append(Node(sub2[:j], [n3]))\n",
        "                    self.nodes[n3].sub = sub2[j:] # old node loses the part in common\n",
        "                    self.nodes[n].ch[x2] = n2\n",
        "                    break # continue down the tree\n",
        "                j = j + 1\n",
        "            i = i + j   # advance past part in common\n",
        "            n = n2      # continue down the tree\n",
        "\n",
        "SuffixTree(text_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUxSrAnUD1wH",
        "outputId": "c153a525-b67c-46b7-849c-95e0784d3ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SuffixTree at 0x7fe589242650>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file= open('text.txt',encoding='utf8')\n",
        "read=file.read()\n",
        "file.seek(0)\n",
        "\n",
        "  \n",
        "# to obtain the\n",
        "# number of lines\n",
        "# in file\n",
        "line = 1\n",
        "for word in read:\n",
        "    if word == '\\n':\n",
        "        line += 1\n",
        "  \n",
        "# create a list to\n",
        "# store each line as\n",
        "# an element of list\n",
        "array = []\n",
        "for i in range(line):\n",
        "    array.append(file.readline())\n",
        "\n",
        "\n",
        "punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
        "for ele in read:  \n",
        "    if ele in punc:  \n",
        "        read = read.replace(ele, \" \")  \n",
        "\n",
        "  \n",
        "# to maintain uniformity\n",
        "read=read.lower()                    \n",
        "\n",
        "\n",
        "for i in range(1):\n",
        "    # this will convert\n",
        "    # the word into tokens\n",
        "    text_tokens = word_tokenize(read)\n",
        "\n",
        "text_tokens"
      ],
      "metadata": {
        "id": "G0rImHqT2myr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post = {}\n",
        "  \n",
        "for i in range(line):\n",
        "    check = array[i].lower()\n",
        "    for item in text_tokens:\n",
        "  \n",
        "        if item in check:\n",
        "            if item not in post:\n",
        "                post[item] = []\n",
        "  \n",
        "            if item in post:\n",
        "              if not i+1 in post[item]:\n",
        "                post[item].append(i+1)\n",
        "  \n",
        "post"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wmEz0zU3f_O",
        "outputId": "700f63a4-c320-460c-d0b7-9a400c332284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'although': [1],\n",
              " 'we': [1, 3, 5],\n",
              " 'know': [1],\n",
              " 'much': [1, 2, 4],\n",
              " 'more': [1],\n",
              " 'about': [1, 4],\n",
              " 'the': [1, 2, 3, 4],\n",
              " 'human': [1],\n",
              " 'brain': [1],\n",
              " 'than': [1],\n",
              " 'did': [1],\n",
              " 'even': [1],\n",
              " 'in': [1, 2],\n",
              " 'a': [1, 2, 3, 4, 5],\n",
              " 'ten': [2],\n",
              " 'years': [2],\n",
              " 'ago': [2],\n",
              " 'thinking': [2],\n",
              " 'it': [2, 3],\n",
              " 'engages': [2],\n",
              " 'remains': [2],\n",
              " 'pretty': [2],\n",
              " 'total': [2],\n",
              " 'mystery': [3],\n",
              " 'is': [3, 4],\n",
              " 'like': [3],\n",
              " 'big': [3],\n",
              " 'jigsaw': [3],\n",
              " 'puzzle': [3],\n",
              " 'where': [3],\n",
              " 'can': [3, 4],\n",
              " 'see': [3],\n",
              " 'many': [3],\n",
              " 'of': [3],\n",
              " 'pieces': [4],\n",
              " 'but': [4],\n",
              " 'not': [4, 5],\n",
              " 'yet': [4],\n",
              " 'put': [4],\n",
              " 'them': [4],\n",
              " 'together': [4],\n",
              " 'there': [4],\n",
              " 'so': [4],\n",
              " 'us': [4],\n",
              " 'that': [5],\n",
              " 'do': [5],\n",
              " 'understand': [5],\n",
              " 'at': [5],\n",
              " 'all': [5]}"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    }
  ]
}